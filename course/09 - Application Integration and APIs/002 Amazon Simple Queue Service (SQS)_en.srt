1
00:00:05,240 --> 00:00:09,710
Hi guys. In this lesson, you're going to learn about the Amazon Simple Queue Service

2
00:00:09,743 --> 00:00:10,740
SQS.

3
00:00:11,090 --> 00:00:15,210
Now to help you understand what an SQS queue is and what benefits it brings,

4
00:00:15,280 --> 00:00:17,060
let's have a look at a diagram.

5
00:00:17,640 --> 00:00:22,270
So I want to give you an example of where you're not using an SQS queue.

6
00:00:22,270 --> 00:00:24,985
So I would call this a direct integration

7
00:00:25,009 --> 00:00:27,660
between different components of an application.

8
00:00:28,040 --> 00:00:32,070
So for example, here we have a web tier on the frontend.

9
00:00:32,070 --> 00:00:35,150
So the web tier is perhaps internet-facing.

10
00:00:35,230 --> 00:00:38,960
And this is where things like orders might be coming in from customers.

11
00:00:39,540 --> 00:00:40,920
You've then got an app tier.

12
00:00:41,220 --> 00:00:45,710
An app tier might process some of the orders or whatever other information

13
00:00:45,735 --> 00:00:47,460
is being received by the web tier.

14
00:00:48,440 --> 00:00:52,250
So the web tier is connected directly to the app tier.

15
00:00:53,140 --> 00:00:55,920
Now one of the downsides of this is the app tier

16
00:00:55,930 --> 00:00:59,460
must keep up with the workload or a failure will occur.

17
00:00:59,940 --> 00:01:04,629
So if the web tier suddenly gets a huge amount of demand, lots of orders are coming in

18
00:01:04,760 --> 00:01:09,703
the app tier must also be able to scale enough to handle those orders.

19
00:01:09,728 --> 00:01:11,380
Now, auto scaling is great.

20
00:01:11,380 --> 00:01:15,070
That will help because it will automatically launch instances.

21
00:01:15,540 --> 00:01:18,840
But those instances can take time to come up and be ready.

22
00:01:18,990 --> 00:01:21,200
So there is a chance that you will lose

23
00:01:21,210 --> 00:01:23,900
information and a customer order could be lost.

24
00:01:24,740 --> 00:01:29,000
So what we could do instead is use a decoupled integration.

25
00:01:29,540 --> 00:01:34,430
Now we have the web tier and the app tier and in the middle we have an SQS queue.

26
00:01:34,610 --> 00:01:38,500
So what happens is the web tier is now integrated to the queue.

27
00:01:38,630 --> 00:01:43,250
It's going to place the orders as messages in the SQS queue.

28
00:01:43,750 --> 00:01:47,390
The app tier is then connecting to the queue, it's polling the queue

29
00:01:47,500 --> 00:01:50,810
and checking, are there any messages I need to process?

30
00:01:51,160 --> 00:01:54,750
Now, if there is a sudden huge amount of information coming in,

31
00:01:54,750 --> 00:01:58,910
lots of orders being placed, then the queue can scale very easily.

32
00:01:58,910 --> 00:02:03,920
So you'll just end up with a lot more orders in the queue awaiting processing.

33
00:02:04,370 --> 00:02:07,800
The app tier may need to scale but it doesn't have the

34
00:02:07,810 --> 00:02:12,080
issue of the direct integration where the orders might be lost because

35
00:02:12,090 --> 00:02:15,070
they can sit in the queue for quite a bit of time

36
00:02:15,080 --> 00:02:18,230
and the app tier can process them as soon as it's ready.

37
00:02:18,740 --> 00:02:21,570
Now, SQS is pull-based not push-based.

38
00:02:21,580 --> 00:02:26,160
A push-based service would be something like SNS, where you're sending

39
00:02:26,160 --> 00:02:29,960
information as a notification. We'll look at that service in this section.

40
00:02:30,340 --> 00:02:32,211
But SQS is pull-based.

41
00:02:32,235 --> 00:02:36,910
And that means as with the previous example on the on the slide I just showed

42
00:02:37,260 --> 00:02:41,560
the instances are polling the queue, they're checking the queue.

43
00:02:41,730 --> 00:02:45,860
The queue is not sending the messages to the EC2,

44
00:02:45,980 --> 00:02:51,200
the instances must connect to the queue and find those messages there.

45
00:02:51,320 --> 00:02:54,311
Now it is possible to trigger some events and we'll look at that

46
00:02:54,335 --> 00:02:55,750
later on in the section.

47
00:02:56,240 --> 00:03:00,000
Messages are up to 256 KB in size.

48
00:03:00,840 --> 00:03:01,810
Larger messages,

49
00:03:01,810 --> 00:03:07,690
So messages above that limitation can be sent using the SQS extended client

50
00:03:07,690 --> 00:03:12,150
library for Java. We'll also look at how that works as well in this section.

51
00:03:12,820 --> 00:03:16,670
Messages can be kept in the queue from one minute up to 14 days.

52
00:03:17,030 --> 00:03:19,860
And the default retention period is four days.

53
00:03:20,070 --> 00:03:25,170
The SQS guarantees that your messages will be processed at least once.

54
00:03:25,440 --> 00:03:27,760
Now there are different queue types to choose from.

55
00:03:28,140 --> 00:03:29,500
We've got a standard queue.

56
00:03:29,860 --> 00:03:32,490
And this has what's called best effort ordering.

57
00:03:32,880 --> 00:03:35,720
Now, best effort ordering doesn't guarantee the ordering

58
00:03:35,720 --> 00:03:37,200
of course, it's best effort.

59
00:03:37,500 --> 00:03:40,640
So though the order, the messages are put on the queue,

60
00:03:40,730 --> 00:03:44,200
maybe the order that they're processed when they're taken from the queue

61
00:03:44,310 --> 00:03:45,660
that's not guaranteed.

62
00:03:45,840 --> 00:03:50,060
So if ordering is very important, then a standard queue is not for you.

63
00:03:50,440 --> 00:03:53,160
Instead, you would use a FIFO queue.

64
00:03:53,940 --> 00:03:57,380
Here we have what's called first in first out delivery.

65
00:03:57,640 --> 00:04:01,150
So the first message, number one here is going to be the first one

66
00:04:01,150 --> 00:04:04,950
to be processed and then number two, three, four, five, six, and so on.

67
00:04:05,340 --> 00:04:09,480
So here's some more differences between a standard queue and a FIFO queue.

68
00:04:09,670 --> 00:04:13,470
With a standard queue, you get unlimited free put and nearly unlimited

69
00:04:13,470 --> 00:04:16,690
transactions per second per API action.

70
00:04:16,980 --> 00:04:18,630
You get best effort ordering

71
00:04:18,769 --> 00:04:22,730
and occasionally messages might be delivered in an order that's different

72
00:04:22,840 --> 00:04:25,050
into which they were put onto the queue.

73
00:04:25,740 --> 00:04:29,640
At least once delivery means the message is delivered at least once,

74
00:04:29,700 --> 00:04:33,960
but occasionally more than one copy of a message could be delivered.

75
00:04:34,200 --> 00:04:36,100
We then have a FIFO queue.

76
00:04:36,260 --> 00:04:38,160
This also supports high throughput.

77
00:04:38,690 --> 00:04:41,800
FIFO queue support up to 300 messages a second.

78
00:04:41,870 --> 00:04:45,550
That's 300 send, receive, or delete operations a second.

79
00:04:46,040 --> 00:04:48,860
You can batch 10 messages per operation.

80
00:04:49,240 --> 00:04:51,550
And that could lead to greater efficiency.

81
00:04:52,040 --> 00:04:57,390
And when you use batching, the FIFO queue can support up to 3000 messages a second.

82
00:04:57,840 --> 00:05:02,710
As I showed on the previous slide, FIFO queues support first in first out delivery.

83
00:05:03,020 --> 00:05:06,410
They also have what's called exactly-once processing.

84
00:05:06,610 --> 00:05:09,540
A message is delivered once and remains available

85
00:05:09,540 --> 00:05:11,890
until the consumer process it and deletes it.

86
00:05:12,040 --> 00:05:14,660
Duplicates are not introduced to the queue.

87
00:05:15,340 --> 00:05:18,520
So it's important to understand what you need for your application.

88
00:05:18,880 --> 00:05:21,620
Does your application logic ensure that the

89
00:05:21,630 --> 00:05:24,000
messages are processed in the correct order

90
00:05:24,240 --> 00:05:26,140
and that there are only processed once?

91
00:05:26,150 --> 00:05:28,650
Or do you require that to be in the queue level

92
00:05:28,650 --> 00:05:30,730
so you don't have to do it in your application?

93
00:05:31,040 --> 00:05:36,180
FIFO queues require the message group ID and message deduplication ID

94
00:05:36,180 --> 00:05:38,170
parameters to be added to messages.

95
00:05:38,540 --> 00:05:42,500
So what are these? Well, let's look at the message group ID first.

96
00:05:42,940 --> 00:05:48,960
This is a tag that specifies that a message belongs to a specific group of messages.

97
00:05:49,380 --> 00:05:54,120
Messages that belong to the same message group are guaranteed to be processed in a

98
00:05:54,145 --> 00:05:55,183
FIFO manner.

99
00:05:55,440 --> 00:05:58,950
If they're not in the same message group, then that is not guaranteed.

100
00:05:59,640 --> 00:06:03,990
Messages with a different group ID could be received out of order.

101
00:06:04,840 --> 00:06:07,240
We then got the deduplication ID.

102
00:06:07,690 --> 00:06:12,700
This is a token used for deduplication of messages within a specified

103
00:06:12,820 --> 00:06:14,560
deduplication interval.

104
00:06:15,210 --> 00:06:17,100
The interval is five minutes.

105
00:06:17,540 --> 00:06:21,170
It's generated as the SHA-256 within the message body.

106
00:06:21,470 --> 00:06:24,900
Now there's another configuration for a queue called a dead letter queue.

107
00:06:25,190 --> 00:06:29,350
It's not exactly a type of queue. It's more of a use case and a configuration.

108
00:06:29,796 --> 00:06:30,920
So what is this?

109
00:06:30,930 --> 00:06:34,685
Well, let's say we got our web tier and application tier again

110
00:06:34,709 --> 00:06:36,260
and we've got an SQS queue.

111
00:06:36,740 --> 00:06:40,660
We then have a separate queue that's configured as a dead letter queue.

112
00:06:41,240 --> 00:06:44,960
Now, what happens is a message is not processed successfully.

113
00:06:48,440 --> 00:06:52,531
In this case the received count metric has exceeded the max received count

114
00:06:52,555 --> 00:06:53,450
for the queue.

115
00:06:53,460 --> 00:06:55,980
What this means is the message has been received

116
00:06:55,980 --> 00:06:59,430
multiple times but it's never been successfully processed.

117
00:06:59,750 --> 00:07:03,650
So there's a max receive count which has been exceeded.

118
00:07:04,040 --> 00:07:07,320
So what happens now is the message could be lost.

119
00:07:07,740 --> 00:07:10,380
But in this case with a dead letter queue,

120
00:07:10,390 --> 00:07:14,920
what happens is that message is now moved over to the dead letter queue.

121
00:07:15,290 --> 00:07:18,400
And that gives us a chance to analyze our failures.

122
00:07:18,510 --> 00:07:22,110
A dead letter queue is actually a standard or FIFO queue

123
00:07:22,250 --> 00:07:24,770
that's been specified as a dead letter queue.

124
00:07:24,770 --> 00:07:28,360
So it's a configuration rather than a different type of queue.

125
00:07:28,730 --> 00:07:32,580
The main task of a dead letter queue is handling message failure.

126
00:07:32,920 --> 00:07:37,050
It lets you set aside and isolate messages that can't be processed correctly

127
00:07:37,200 --> 00:07:39,760
so that you can then analyze why that happened.

128
00:07:40,210 --> 00:07:42,100
It's not a queue type as I mentioned,

129
00:07:42,130 --> 00:07:44,740
it's a standard or FIFO queue that you've configured

130
00:07:44,860 --> 00:07:46,110
as a dead letter queue.

131
00:07:46,510 --> 00:07:47,550
And this is where you do it.

132
00:07:48,140 --> 00:07:51,040
You enable something called a redrive policy.

133
00:07:51,190 --> 00:07:54,770
You specify the queue to use as the dead letter queue.

134
00:07:54,890 --> 00:07:58,270
So that's the name of my dead letter queue, My DL queue.

135
00:07:58,450 --> 00:08:02,660
And you specify the maximum receives before a message is sent

136
00:08:02,820 --> 00:08:03,950
to the dead letter queue.

137
00:08:03,950 --> 00:08:07,760
So that's that max receive count that we saw on the previous slide.

138
00:08:08,010 --> 00:08:10,170
Messages are moved to the dead letter queue

139
00:08:10,170 --> 00:08:14,560
when the receive count for a message exceeds the max receive count for the queue.

140
00:08:15,040 --> 00:08:16,790
Dead letter queues should not be used with

141
00:08:16,790 --> 00:08:21,310
standard queues when your application will keep retrying transmission.

142
00:08:21,520 --> 00:08:25,410
And that's because you don't want that message to now be moved into

143
00:08:25,435 --> 00:08:27,540
a dead letter queue because your application is going to

144
00:08:27,540 --> 00:08:30,550
keep on attempting to process that message.

145
00:08:31,140 --> 00:08:34,890
Dead letter queues will break the order of messages in FIFO queues.

146
00:08:35,440 --> 00:08:39,380
There's another queue configuration that we call a delay queue. So what is this?

147
00:08:39,549 --> 00:08:41,789
So again, we have our SQS queue.

148
00:08:41,820 --> 00:08:44,240
We have a producer that's the instance that's

149
00:08:44,240 --> 00:08:46,740
going to be placing messages onto our queue.

150
00:08:47,070 --> 00:08:48,520
And it places a message.

151
00:08:48,730 --> 00:08:53,570
Now I'm indicating the timeline here of the message as it's in the queue.

152
00:08:53,570 --> 00:08:57,250
So over time, what is going to happen to that message in the queue.

153
00:08:57,740 --> 00:09:00,791
So what we do with a delay queue is we've configured something

154
00:09:00,815 --> 00:09:02,180
called a delay seconds.

155
00:09:02,740 --> 00:09:04,750
Now let's say we have a Lambda function.

156
00:09:04,870 --> 00:09:06,660
This is the processing component.

157
00:09:06,670 --> 00:09:10,360
It's going to try and find the messages in the queue and process them.

158
00:09:10,710 --> 00:09:13,260
So the function is polling the queue.

159
00:09:13,480 --> 00:09:19,310
But at this point in the timeline, the message is still within the delay seconds.

160
00:09:19,440 --> 00:09:24,070
That means that Lambda cannot find that message in the queue. It's not even visible.

161
00:09:24,540 --> 00:09:30,250
Now as time goes on, the delay seconds is past now the message becomes visible again

162
00:09:30,420 --> 00:09:33,380
and the lambda function can process that message.

163
00:09:33,600 --> 00:09:36,611
Now, we can configure this through the delivery delay.

164
00:09:36,635 --> 00:09:38,560
So you can see that just down here.

165
00:09:38,720 --> 00:09:42,150
The default is zero seconds. So that means it's not enabled,

166
00:09:42,340 --> 00:09:44,610
And the max is 15 minutes.

167
00:09:45,040 --> 00:09:47,010
So when would you use a delay queue?

168
00:09:47,030 --> 00:09:50,290
Well, maybe with large distributed applications that need

169
00:09:50,290 --> 00:09:52,640
to introduce a delay in processing,

170
00:09:52,860 --> 00:09:57,430
you need to apply a delay to an entire queue of messages for some reason.

171
00:09:57,780 --> 00:10:01,790
And one example might be you're adding a delay of a few seconds to allow

172
00:10:01,800 --> 00:10:05,350
updates to sales or stock control databases

173
00:10:05,440 --> 00:10:10,260
before sending a notification to a customer confirming an online transaction.

174
00:10:10,640 --> 00:10:14,060
You also need to understand what the visibility timeouts is.

175
00:10:14,310 --> 00:10:18,170
So we've got a similar configuration here to the previous diagram.

176
00:10:18,195 --> 00:10:22,430
We've got a producer and a consumer, both EC2 instances in this case.

177
00:10:23,040 --> 00:10:25,185
So a message gets placed on the queue,

178
00:10:25,209 --> 00:10:28,210
there's the delay seconds and the message cannot be returned

179
00:10:28,235 --> 00:10:29,460
because it's not visible.

180
00:10:29,800 --> 00:10:32,350
Then of course the message does become visible

181
00:10:32,510 --> 00:10:35,550
and the instance is able to process that message.

182
00:10:36,240 --> 00:10:39,560
Now, we could then have something called a visibility timeout.

183
00:10:39,940 --> 00:10:44,771
Now, what this means is the message is invisible for a period of time.

184
00:10:44,795 --> 00:10:45,960
Now, you might say, well hang on,

185
00:10:45,960 --> 00:10:50,650
it's just been processed but well, it might not processed successfully.

186
00:10:51,010 --> 00:10:53,320
So the message is not deleted from the queue

187
00:10:53,320 --> 00:10:56,950
when an instance actually starts processing that message.

188
00:10:57,440 --> 00:10:59,580
So the visibility timeout gives you a

189
00:10:59,580 --> 00:11:03,170
period of time in which the message is invisible

190
00:11:03,350 --> 00:11:07,460
and therefore can't be processed by any other EC2 instances.

191
00:11:08,340 --> 00:11:11,460
Now let's say the message fails to process for some reason.

192
00:11:12,040 --> 00:11:16,850
Now, after a period of time, after the visibility timeout expires,

193
00:11:17,120 --> 00:11:19,000
the message becomes visible again.

194
00:11:19,300 --> 00:11:22,730
And that means another instance or the same instance

195
00:11:22,840 --> 00:11:25,090
can try and process that message again.

196
00:11:25,450 --> 00:11:29,070
So the visibility timeout is the amount of time a message

197
00:11:29,080 --> 00:11:33,360
is invisible in the queue after a reader picks it up.

198
00:11:33,840 --> 00:11:37,860
Provided the job is process before the visibility timeout expires,

199
00:11:38,000 --> 00:11:40,600
the message will then be deleted from the queue.

200
00:11:40,830 --> 00:11:44,310
If the job's not processed within the visibility timeout,

201
00:11:44,310 --> 00:11:49,905
the message will become visible again and then it's available for another processor,

202
00:11:49,930 --> 00:11:53,390
another consumer to actually pick that message up and process it.

203
00:11:53,610 --> 00:11:56,860
This could result in the same message being delivered twice.

204
00:11:57,140 --> 00:12:01,870
So again, sometimes you need to think about where is going to be the logic to ensure

205
00:12:01,870 --> 00:12:05,560
that this doesn't happen if it's going to be an issue with your application.

206
00:12:06,340 --> 00:12:12,160
The default visibility timeout is 30 seconds, the maximum is 12 hours.

207
00:12:12,640 --> 00:12:16,600
And here's a view into the configuration in the console where in

208
00:12:16,600 --> 00:12:19,960
this case we have the default timeout of 30 seconds.

209
00:12:20,340 --> 00:12:24,360
Moving on, we have something called long polling and short polling.

210
00:12:24,740 --> 00:12:27,750
And it's really important in the exam to understand the differences

211
00:12:27,750 --> 00:12:31,530
and the benefits and drawbacks of using either of these methods.

212
00:12:31,650 --> 00:12:34,300
Of course, polling is where we're looking at the

213
00:12:34,300 --> 00:12:37,890
queue and checking if messages are available to be processed.

214
00:12:38,170 --> 00:12:43,100
With short polling, the instance will check a subset of servers

215
00:12:43,230 --> 00:12:45,450
and may not return all messages.

216
00:12:46,440 --> 00:12:48,480
So perhaps it doesn't find the message.

217
00:12:48,760 --> 00:12:50,930
Upon a retry, maybe it does.

218
00:12:51,440 --> 00:12:53,860
On the other hand, with long polling

219
00:12:54,240 --> 00:12:58,060
we're more likely to receive the message because long polling waits

220
00:12:58,170 --> 00:13:01,650
for the wait time seconds, which is a configurable value

221
00:13:02,040 --> 00:13:04,480
and eliminates empty responses.

222
00:13:04,650 --> 00:13:08,400
So as long as the wait time seconds is configured long enough,

223
00:13:08,410 --> 00:13:12,760
then it means that it's going to find messages as they appear in the queue.

224
00:13:12,820 --> 00:13:17,610
So essentially you're creating an API action, you're executing an API action,

225
00:13:18,040 --> 00:13:24,251
and you're waiting to make sure that it results in actually picking up a message

226
00:13:24,275 --> 00:13:25,410
and processing it.

227
00:13:25,590 --> 00:13:27,580
With short polling. That's not happening.

228
00:13:27,700 --> 00:13:29,830
You're checking, you missed the messages.

229
00:13:29,840 --> 00:13:32,760
Either they're not there or you don't find them on the right servers

230
00:13:33,140 --> 00:13:38,220
and then you have to issue another API action to repeat the process.

231
00:13:38,330 --> 00:13:40,550
Now that can result in higher costs because

232
00:13:40,550 --> 00:13:44,210
you are charged for executing those API actions.

233
00:13:44,310 --> 00:13:47,800
So long polling is a way to retrieve messages from queues

234
00:13:47,936 --> 00:13:50,655
and it waits for the messages to arrive.

235
00:13:50,680 --> 00:13:55,070
Short polling returns immediately even if the message queue is empty.

236
00:13:55,540 --> 00:13:57,710
Long polling can lower costs.

237
00:13:58,100 --> 00:14:01,010
Long polling is enabled at queue level or you can

238
00:14:01,010 --> 00:14:05,200
do it at the API level using the wait time seconds parameter.

239
00:14:05,940 --> 00:14:10,040
Long polling is in effect when the received message wait time

240
00:14:10,200 --> 00:14:14,930
is a value greater than zero seconds and up to 20 seconds.

241
00:14:15,280 --> 00:14:18,010
And here you can see where you configure this in the console.

242
00:14:18,010 --> 00:14:19,900
We've got the receive message wait time

243
00:14:20,050 --> 00:14:23,993
and that's configured in this case to the maximum of 20 seconds

